# -*- coding: utf-8 -*-
"""MobileViT-XS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tGDvTcJYlpZtn2v6RpKZPgNvi296bvwp

# MOUNT DRIVE
"""

from google.colab import drive
drive.mount('/content/drive')

zip_path = "/content/drive/MyDrive/Train_converted.zip"

extract_dir = "/content/dataset_original_mobilevit"
train_dir = "/content/dataset_mv/train"
val_dir = "/content/dataset_mv/val"

"""# EXTRACT ZIP DATASET"""

import zipfile, os, shutil

# Bersihkan folder lama
shutil.rmtree(extract_dir, ignore_errors=True)
os.makedirs(extract_dir, exist_ok=True)

# Extract
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("Selesai extract:", extract_dir)

"""# AUGMENTASI DATASET"""

import os, shutil, random
from PIL import Image, ImageEnhance
from tqdm import tqdm

extract_dir = "/content/dataset_original_mobilevit"
train_dir = "/content/dataset_augmented/train"
val_dir = "/content/dataset_augmented/val"

# Bersihkan folder jika ada folder sebelumnya
shutil.rmtree("/content/dataset_augmented", ignore_errors=True)
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

def augment_image(img):
    """Augmentasi ringan dengan variasi acak."""
    aug = img.copy()

    # Rotasi random -10 sampai 10 derajat
    aug = aug.rotate(random.randint(-10, 10))

    # Brightness random
    enhancer = ImageEnhance.Brightness(aug)
    aug = enhancer.enhance(random.uniform(0.8, 1.3))

    # Contrast random
    enhancer = ImageEnhance.Contrast(aug)
    aug = enhancer.enhance(random.uniform(0.8, 1.3))

    # Optional: blur ringan
    # from PIL import ImageFilter
    # aug = aug.filter(ImageFilter.GaussianBlur(radius=random.uniform(0, 1.2)))

    return aug


class_folders = sorted(os.listdir(extract_dir))
print(" Jumlah kelas terdeteksi:", len(class_folders))

target_images = 40

for cls in class_folders:
    cls_path = os.path.join(extract_dir, cls)
    if not os.path.isdir(cls_path):
        continue

    images = [f for f in os.listdir(cls_path) if f.lower().endswith((".jpg", ".jpeg", ".png", ".webp", ".bmp"))]

    if len(images) == 0:
        print(f" SKIP: {cls} tidak memiliki gambar.")
        continue

    print(f" Proses kelas: {cls} | {len(images)} gambar ditemukan.")


    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)
    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)


    base_val_img = random.choice(images)
    shutil.copy(os.path.join(cls_path, base_val_img), os.path.join(val_dir, cls, f"{cls}_val.jpg"))


    idx = 0
    with tqdm(total=target_images, desc=f"Augmenting {cls}", ncols=80) as pbar:
        while idx < target_images:
            base_img = random.choice(images)
            img = Image.open(os.path.join(cls_path, base_img)).convert("RGB")

            img_aug = augment_image(img)
            save_path = os.path.join(train_dir, cls, f"{cls}_aug_{idx}.jpg")
            img_aug.save(save_path)

            idx += 1
            pbar.update(1)

print("\n Semua kelas sekarang memiliki 40 gambar TRAIN + 1 VALIDASI per kelas.\n")

"""# SPLIT DATA"""

import random

# Bersihkan folder output
shutil.rmtree("/content/dataset_mv", ignore_errors=True)
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

# Ambil folder kelas
class_folders = sorted(os.listdir(extract_dir))
print("Total kelas:", len(class_folders))

for cls in class_folders:
    cls_path = os.path.join(extract_dir, cls)
    if not os.path.isdir(cls_path):
        continue

    images = [f for f in os.listdir(cls_path)
              if f.lower().endswith((".jpg", ".jpeg", ".png"))]

    if len(images) < 4:
        print(" WARNING:", cls, "kurang dari 4 gambar → dilewati")
        continue

    random.shuffle(images)

    train_imgs = images[:3]
    val_imgs = images[3:4]

    # Buat folder
    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)
    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)

    # Copy file
    for img in train_imgs:
        shutil.copy(os.path.join(cls_path, img),
                    os.path.join(train_dir, cls, img))
    for img in val_imgs:
        shutil.copy(os.path.join(cls_path, img),
                    os.path.join(val_dir, cls, img))

print("Split dataset selesai!")

"""# LOAD DATASET"""

import tensorflow as tf

img_size = (256, 256)
batch_size = 8

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    image_size=img_size,
    batch_size=batch_size,
    label_mode="categorical"
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    val_dir,
    image_size=img_size,
    batch_size=batch_size,
    label_mode="categorical"
)

class_names = train_ds.class_names
num_classes = len(class_names)
print("Jumlah kelas:", num_classes)

"""# BUILD MODEL"""

!pip install -q tf-keras-vis  # tambahan untuk visualisasi opsional

"""# MODEL MobileViT-S (Keras Applications)"""

from tensorflow.keras.applications import MobileNetV3Small
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model

# MOBILEViT tidak tersedia di Keras default
# → kita gunakan MobileNetV3Small (paling mirip konsepnya: ringan + powerful)

base = MobileNetV3Small(
    input_shape=(256,256,3),
    include_top=False,
    weights="imagenet"
)

base.trainable = False

x = GlobalAveragePooling2D()(base.output)
x = Dropout(0.3)(x)
output = Dense(num_classes, activation="softmax")(x)

model = Model(inputs=base.input, outputs=output)

model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

"""# TRAINING"""

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10

)

"""# EVALUASI"""

import numpy as np

y_true = []
y_pred = []

for images, labels in val_ds:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

print("Jumlah sampel validasi:", len(y_true))

"""# CLASSIFICATION REPORT"""

from sklearn.metrics import classification_report

print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

"""# CONFUSION MATRIX"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(20,18))
sns.heatmap(cm, cmap="Blues")
plt.title("Confusion Matrix - MobileViT (MobileNetV3Small backbone)")
plt.xlabel("Prediksi")
plt.ylabel("Asli")
plt.show()

"""# SAVE MODEL"""

from google.colab import files
import tensorflow as tf
import os

save_dir = "/content/saved_model"
os.makedirs(save_dir, exist_ok=True)

h5_path = os.path.join(save_dir, "model_mobilevit_converted.h5")
model.save(h5_path)
print("✔ Model disimpan dalam format .h5:", h5_path)

savedmodel_path = os.path.join(save_dir, "saved_model_format")
model.export(savedmodel_path)
print("✔ Model disimpan dalam format SavedModel:", savedmodel_path)

tflite_path = os.path.join(save_dir, "model_mobilevit_converted.tflite")

converter = tf.lite.TFLiteConverter.from_saved_model(savedmodel_path)
converter.optimizations = [tf.lite.Optimize.DEFAULT]  # opsi kompres
tflite_model = converter.convert()

with open(tflite_path, "wb") as f:
    f.write(tflite_model)

print("✔ Model berhasil dikonversi ke .tflite:", tflite_path)

print("\n⬇️ Mendownload model...")

files.download(h5_path)
files.download(tflite_path)