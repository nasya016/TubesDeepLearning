# -*- coding: utf-8 -*-
"""MobileNetV2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zd8BD4__lFLD0hUeW5oFJsEr3sjM8Thx

# MOUNT DRIVE
"""

from google.colab import drive
drive.mount('/content/drive')

"""# EXTRACT ZIP DATASET"""

import zipfile, os, shutil

zip_path = "/content/drive/MyDrive/train_converted.zip"   # <-- dataset kamu
extract_dir = "/content/dataset_original"

if os.path.exists(extract_dir):
    shutil.rmtree(extract_dir)
os.makedirs(extract_dir, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print("Dataset berhasil diekstrak ke:", extract_dir)

"""# SPLIT DATA + AUGMENTASI (PER KELAS)"""

import random
from PIL import Image, ImageEnhance, ImageFilter
import numpy as np

train_dir = "/content/dataset/train"
val_dir = "/content/dataset/val"

shutil.rmtree("/content/dataset", ignore_errors=True)
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

def augment_image(img):
    """Melakukan augmentasi ringan."""
    aug = img.copy()

    # Rotasi kecil
    aug = aug.rotate(random.randint(-10, 10))

    # Brightness
    enhancer = ImageEnhance.Brightness(aug)
    aug = enhancer.enhance(random.uniform(0.7, 1.3))

    # Contrast
    enhancer = ImageEnhance.Contrast(aug)
    aug = enhancer.enhance(random.uniform(0.7, 1.3))

    return aug

class_folders = sorted(os.listdir(extract_dir))
print("Jumlah kelas:", len(class_folders))

target_images = 40  # <-- setiap kelas ingin dibuat 40 gambar augmented

for cls in class_folders:
    cls_path = os.path.join(extract_dir, cls)
    if not os.path.isdir(cls_path):
        continue

    images = [f for f in os.listdir(cls_path) if f.lower().endswith((".jpg",".jpeg",".png",".webp",".bmp"))]

    if len(images) < 1:
        print("SKIP:", cls, "tidak punya gambar.")
        continue

    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)
    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)

    # ====== COPY 1 GAMBAR KE VALIDASI ======
    val_img = images[0]
    shutil.copy(os.path.join(cls_path, val_img), os.path.join(val_dir, cls, val_img))

    # ====== AUGMENT UNTUK TRAIN ======
    for idx in range(target_images):
        base_img = random.choice(images)
        img = Image.open(os.path.join(cls_path, base_img)).convert("RGB")

        # augment
        img_aug = augment_image(img)

        save_path = os.path.join(train_dir, cls, f"{cls}_aug_{idx}.jpg")
        img_aug.save(save_path)

print("Augmentasi selesai! Semua kelas memiliki 40 gambar train.")

"""# DATASET PIPELINE"""

import tensorflow as tf

img_size = (224, 224)
batch_size = 16

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    image_size=img_size,
    batch_size=batch_size,
    label_mode="categorical",
    shuffle=True
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    val_dir,
    image_size=img_size,
    batch_size=batch_size,
    label_mode="categorical",
    shuffle=False
)

class_names = train_ds.class_names
num_classes = len(class_names)
print("Total kelas:", num_classes)

"""# BANGUN MODEL MOBILENETV2"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model

base = MobileNetV2(input_shape=(224,224,3), include_top=False, weights="imagenet")
base.trainable = False

x = GlobalAveragePooling2D()(base.output)
x = Dropout(0.3)(x)
output = Dense(num_classes, activation="softmax")(x)

model = Model(inputs=base.input, outputs=output)

model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

"""# TRAINING MODEL"""

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=7
)

"""# EVALUASI MODEL"""

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

y_true = []
y_pred = []

for images, labels in val_ds:
    preds = model.predict(images)
    y_pred.extend(np.argmax(preds, axis=1))
    y_true.extend(np.argmax(labels.numpy(), axis=1))

print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(20, 18))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.title("Confusion Matrix - MobileNetV2")
plt.xlabel("Prediksi")
plt.ylabel("Asli")
plt.show()

model.export("mobilenetv2_savedmodel")

import shutil
shutil.make_archive("mobilenetv2_savedmodel", "zip", "mobilenetv2_savedmodel")

from google.colab import files
files.download("mobilenetv2_savedmodel.zip")